{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will practice wrangling data through different formats, with missing data, and working with text.\n",
    "\n",
    "You may or may not use `for` loops depending on the questions. **Please see the question instructions carefully to determine if `for` loops can be used.** Generally, you should never be iterating over the rows of a DataFrame using `for` loops. If you do, you will lose points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Text wrangling and regular expressions\n",
    "In this part, we will work with the citation file exported from the [Nature Review Article](https://www.nature.com/articles/s41586-020-2649-2) *Array Programming with NumPy*. Below we read the file into the Python variable `cite` and print the result for you to preview.\n",
    "\n",
    "It is fine to use `for` loops in this part since it involves parsing code before putting them into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TY  - JOUR\n",
      "AU  - Harris, Charles R.\n",
      "AU  - Millman, K. Jarrod\n",
      "AU  - van der Walt, Stéfan J.\n",
      "AU  - Gommers, Ralf\n",
      "AU  - Virtanen, Pauli\n",
      "AU  - Cournapeau, David\n",
      "AU  - Wieser, Eric\n",
      "AU  - Taylor, Julian\n",
      "AU  - Berg, Sebastian\n",
      "AU  - Smith, Nathaniel J.\n",
      "AU  - Kern, Robert\n",
      "AU  - Picus, Matti\n",
      "AU  - Hoyer, Stephan\n",
      "AU  - van Kerkwijk, Marten H.\n",
      "AU  - Brett, Matthew\n",
      "AU  - Haldane, Allan\n",
      "AU  - del Río, Jaime Fernández\n",
      "AU  - Wiebe, Mark\n",
      "AU  - Peterson, Pearu\n",
      "AU  - Gérard-Marchant, Pierre\n",
      "AU  - Sheppard, Kevin\n",
      "AU  - Reddy, Tyler\n",
      "AU  - Weckesser, Warren\n",
      "AU  - Abbasi, Hameer\n",
      "AU  - Gohlke, Christoph\n",
      "AU  - Oliphant, Travis E.\n",
      "PY  - 2020\n",
      "DA  - 2020/09/01\n",
      "TI  - Array programming with NumPy\n",
      "JO  - Nature\n",
      "SP  - 357\n",
      "EP  - 362\n",
      "VL  - 585\n",
      "IS  - 7825\n",
      "AB  - Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.\n",
      "SN  - 1476-4687\n",
      "UR  - https://doi.org/10.1038/s41586-020-2649-2\n",
      "DO  - 10.1038/s41586-020-2649-2\n",
      "ID  - Harris2020\n",
      "ER  - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "with open(\"numpy_nature.txt\") as f:\n",
    "    cite = f.read()\n",
    "\n",
    "print(cite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (4 points)\n",
    "There are several authors, each recorded on a separate line beginning with `AU`. In the variable `q1` put a Python list of all of the author names formatted as in the file but without the extra characters and whitespace (i.e., without the `AU  - ` or the newline `\\n` characters). Your list should be of the form `['Harris, Charles R.', 'Millman, K. Jarrod', ..., 'Oliphant, Travis E.']`. When you are finished, print the resulting list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your code to answer the question here, and store the answer as the following variable\n",
    "# Please keep author names in the original order\n",
    "\n",
    "q1 = ... # List of Authors\n",
    "\n",
    "\n",
    "print(q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (4 points)\n",
    "Create a Pandas DataFrame that contains three columns: one for first names, one for middle names, and one for last names for all of the authors. Use the column names of the example table below. Keep the same order as the original text file and use the default primary index (the row labels) of 0, 1, 2, etc. as shown below. You are welcome to use the results of the prior question to asnwer this problem.\n",
    "\n",
    "|      | first      | middle     | last         |\n",
    "| ---- | ---------- | ---------- | ------------ |\n",
    "| 0\t   | Charles    | R.         | Harris       |\n",
    "| 1\t   | K.\t        | Jarrod     | Millman      |\n",
    "| 2\t   | Stéfan     | J.         | van der Walt |\n",
    "| 3    | Ralf       |            | Gommers      |\n",
    "| 4\t   | Pauli      |            | Virtanen     |   \n",
    "\n",
    "Note that some authors do not have any middle names, in which case you can leave the middle name column blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run but do not modify this code\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your code to answer the question here, and store the answer as the following variable\n",
    "# Please keep author names in the original order\n",
    "\n",
    "q2 = ... # Pandas DataFrame with three columns\n",
    "\n",
    "...\n",
    "\n",
    "q2 # This last line will display the table to check for correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (12 points)\n",
    "Below we extract the abstract from the citation and store it in a string variable `abstract`. Write regular expressions to answer the following questions about the abstract.\n",
    "\n",
    "1. In `q3_1` put the starting index of everywhere `NumPy` appears in the abstract (i.e., the index of the `N` wherever `NumPy` occurs in the `abstract` string). This should be case sensitive.\n",
    "2. In `q3_2` put all of the capitalized words in `abstract`, including words with extra capitalized letters like `NumPy` and `NumPy-like`.\n",
    "3. In `q3_3` put all of the words that immediately follow `NumPy`, but do not include the word `NumPy` itself. For the one occurrence it is hyphenated `NumPy-like`, use `-like`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run but do not modify this code\n",
    "import re\n",
    "abstract_query = re.compile(r\"AB  - (.+)\")\n",
    "abstract = re.search(abstract_query, cite).group(1)\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your code to answer the question here, and store the answer as the following variable\n",
    "# Please allow duplication in your list\n",
    "\n",
    "q3_1 = ... # List of index\n",
    "q3_2 = ... # List of all the capitalized words\n",
    "q3_3 = ... # List of words that immediately follow Numpy\n",
    "\n",
    "...\n",
    "\n",
    "# Run but do not modify this code\n",
    "print('q3_1:', q3_1)\n",
    "print('q3_2:', q3_2)\n",
    "print('q3_3:', q3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Cleaning up more system logs CSV\n",
    "\n",
    "In this part, we work with a piece of messy tabular data in the form of a poorly formatted csv file containing data about programs running on computer systems. It contains all of the data about system time and memory from Worked Example 4, but also includes new information about user ids and machine ids, and some data are missing in every column. (The user ids are made up and do not correspond to any real individuals)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (12 points, 2 manual points)\n",
    "\n",
    "Below, we import the dataset using the Pandas `read_csv` function that creates a dataframe. Run the code; it will preview the first five rows.\n",
    "\n",
    "**Do not** use `for` loops, unless it is guaranteed to iterate less than 50 times. The manual points are partially for checking for this. You are also likely to not pass some tests because iterating over the entire `DataFrame` sometimes causes issues with formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run but do not modify this code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys_df = pd.read_csv(\"more_monitor.csv\")\n",
    "sys_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several formatting issues with the default import. Address the following.\n",
    "\n",
    "1. The `System User ID` and `System Machine ID` contain String data with the redundant information `User ID: ` and `Machine ID: ` in every row that has data. Remove these prefixes so that the columns only contain the user ids and machine ids themselves. Leave the `?` cells as is. For example, the first row should just have `yw22` in the `System User ID` column and `Carrot` in the `System Machine ID` column, while the second row should keep `?` for both columns.\n",
    "\n",
    "2. The first three rows for `System Time second`, `System Memory GB` and `System Memory MB` contain numerical data but are currently formatted as strings with redundant prefix information repeating the column label and missing data represented as the string `?` instead of the Numpy `NaN` sentinel value. Fix this so that each value in the first three columns is either a single numerical value or `NaN` (note, you should use the actual `np.NaN` sentinal value, not just the String with the characters `N`, `a`, and `N`). For example, when you are done, the first three columns of the first row should all have `NaN` values, the second row should be `40`, `3`, and `382`, and so on. Note that the rows at index `400` and on have System Time recorded in minutes instead of seconds, be sure to convert these to seconds by mulitplying by 60.\n",
    "\n",
    "3. Currently the System Memory is split accross two columns, one for the GB and one for the MB. For example, the total memory of the first program is 3 GB and 414 MB. Instead, represent the full system memory in the `System Memory GB` column, and get rid of the `System Memory MB` column. To do so, you need to convert the values in the MB column to GB (1 MB is 0.001 GB) and add that to the GB column, then use the [`drop` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html). Missing values should remain missing after this transformation.\n",
    "\n",
    "When you are finished, `sys_df` should have the above issues corrected. Run both of the cells with `sys_df.head()` and `sys_df.tail()` to show the first and last few rows of your dataframe. Create a variable `q4` and have it point to this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your code to answer the question here, and store sys_df in q4 for full credit\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "q4 = sys_df\n",
    "\n",
    "# Run but do not modify this code\n",
    "print(q4.head())\n",
    "\n",
    "# Run but do not modify this code\n",
    "print(q4.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (12 points)\n",
    "The `sys_df` dataframe from question 4 should now be a little easier to read and use. Answer the following questions about `sys_df`.\n",
    "\n",
    "1. How many rows are missing data (have a `?`) in the `System Machine ID` column? Put your answer in `q5_1`.\n",
    "2. What is the average value of `System Memory GB` among the rows that are missing data (have a `?`) in the `System User ID` column?  Put your answer in `q5_2`.\n",
    "3. How many rows are missing data in both the `System Time second` and `System Memory GB` columns? Put your answer in `q5_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your code to answer the question here, and store answers as the following variables\n",
    "\n",
    "q5_1 = ... # number of rows\n",
    "q5_2 = ... # average System Memory GB\n",
    "q5_3 = ... # number of missing rows\n",
    "\n",
    "...\n",
    "\n",
    "# Run but do not modify this code\n",
    "print('q5_1:', q5_1)\n",
    "print('q5_2:', q5_2)\n",
    "print('q5_3:', q5_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Wrangling FDA JSON Dataset \n",
    "In this part we work with a messy JSON dataset containing information about several drugs labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 (12 points)\n",
    "Below we import the `FDADrugLabel.json` file into the `labels` variable. This is the same dataset as the worked example. The resulting Python object is somewhat messy; we encourage you to explore the data before answering the questions.\n",
    "\n",
    "You may use `for` loops for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run but do not modify this code\n",
    "import json\n",
    "with open(\"FDADrugLabel.json\", encoding=\"utf-8\") as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to explore (and you are welcome to add more cells as needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions.\n",
    "\n",
    "1. In `q6_1` put the average number of key/value (or name/value) pairs for the drugs.\n",
    "\n",
    "2. In `q6_2` put the list of all of the `manufacturer_names` without any other information. `manufacturer_names` are not a top level key/name, you will need to search for where they are located and how to extract them.\n",
    "\n",
    "3. In `q6_3` put how many drugs contain the string `child` anywhere in their `warnings` (including as part of larger strings like `children`). Note: `warnings` is a top level key/name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your code to answer the question here, and store answers as the following variables\n",
    "\n",
    "q6_1 = ... # number of rows\n",
    "q6_2 = ... # average System Memory GB\n",
    "q6_3 = ... # number of missing rows\n",
    "\n",
    "...\n",
    "\n",
    "# Run but do not modify this code\n",
    "print('q6_1:', q6_1)\n",
    "print('q6_2:', q6_2)\n",
    "print('q6_3:', q6_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting\n",
    "\n",
    "You should make sure any code that you write to answer the questions is included in this notebook. We recommend you go to the Kernel option and choose \\\"Restart & Run All.\\\" Double check that your entire notebook runs correctly and generates the expected output. Finally, make sure to save your work (timestamp at the top tells you the last checkpoint and whether there are unsaved changes). When you finish, submit your assignment at [Gradescope](http://gradescope.com/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": [
      2,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q1, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q1_1\n>>> check_q1_1(q1)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q1_2\n>>> check_q1_2(q1)\n'PASS'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": [
      1,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q2.shape == (26, 3)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 'first' in q2.columns and 'middle' in q2.columns and 'last' in q2.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q2_1\n>>> check_q2_1(q2)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q2_2\n>>> check_q2_2(q2)\n'PASS'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": [
      2,
      2,
      2,
      2,
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q3_1, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q3_1\n>>> check_q3_1(q3_1)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(q3_2, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q3_2\n>>> check_q3_2(q3_2)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(q3_3, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q3_3\n>>> check_q3_3(q3_3)\n'PASS'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": [
      1,
      1,
      1,
      1,
      2,
      2,
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'User ID:' not in q4.loc[(0, 'System User ID')] and 'Machine ID:' not in q4.loc[(0, 'System Machine ID')] \nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Confirm that q4's row 1's user and machine id column values are ?\n>>> q4.iloc[1]['System User ID'] == \"?\" and q4.iloc[1]['System Machine ID'] == \"?\"\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q4_1\n>>> check_q4_1(q4)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q4_2\n>>> check_q4_2(q4)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q4.loc[([0,1], ['System Time second', 'System Memory GB'])]\n   System Time second  System Memory GB\n0                 NaN               NaN\n1                40.0             3.382",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q4_3\n>>> check_q4_3(q4)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 'System Memory MB' not in q4.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q4_4\n>>> check_q4_4(q4)\n'PASS'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": [
      2,
      2,
      2,
      2,
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q5_1, int) or isinstance(q5_1, np.int64)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q5_1\n>>> check_q5_1(q5_1)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(q5_2, float) or isinstance(q5_2, np.float64)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q5_2\n>>> check_q5_2(q5_2)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(q5_3, int) or isinstance(q5_3, np.int64)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q5_3\n>>> check_q5_3(q5_3)\n'PASS'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": [
      2,
      2,
      1,
      1,
      2,
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q6_1, float) or isinstance(q6_1, np.float64)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q6_1\n>>> check_q6_1(q6_1)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(q6_2, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Check type of the values in the list in q6_2\n>>> all([type(x) == str for x in q6_2])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q6_2\n>>> check_q6_2(q6_2)\n'PASS'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(q6_3, int) or isinstance(q6_3, np.int64)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from auto_checks import check_q6_3\n>>> check_q6_3(q6_3)\n'PASS'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
